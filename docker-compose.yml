services:
  nginxproxymanager:
    image: 'jc21/nginx-proxy-manager:latest'
    environment:
      - PUID=1001
      - PGID=1001
    ports:
      - mode: host
        target: 80
        published: 80
        protocol: tcp
      - mode: host
        target: 81
        published: 81
        protocol: tcp
      - mode: host
        target: 443
        published: 443
        protocol: tcp
    volumes:
      - ./nginx/data/:/data
      - ./nginx/letsencrypt:/etc/letsencrypt
      - ./static:/data/static
      - ./media:/data/media
    networks:
      - net
    stop_grace_period: 5s
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure

  #  pgadmin:
  #    image: dpage/pgadmin4
  #    hostname: pgadmin
  #    environment:
  #      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
  #      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
  #    ports:
  #      - "5050:80"
  #    networks:
  #      - net
  #    deploy:
  #      replicas: 1
  #      update_config:
  #        parallelism: 1
  #        delay: 10s
  #      restart_policy:
  #        condition: on-failure
  #      resources:
  #        limits:
  #          cpus: '0.4'
  #          memory: 256M
  #        reservations:
  #          memory: 128M

  redis:
    user: 1000:1001
    hostname: redis
    image: redis:alpine
    volumes:
      - ./data/redis/:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
    #    ports:
    #       - "6379:6379"
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      timeout: 5s
      retries: 10
      start_period: 5s
    command: [ "redis-server", "/usr/local/etc/redis/redis.conf" ]
    networks:
      - net
    stop_grace_period: 5s
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      resources:
        limits:
          cpus: '0.5'
          memory: 4G
        reservations:
          cpus: '0.25'
          memory: 512M

  web:
    hostname: web
    image: localhost:5000/iweb:latest
    environment:
      - DB_NAME=${DB_NAME}
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_HOST=${DB_HOST}
      - DB_PORT=${DB_PORT}
      - LOG_PREFIX=server
    volumes:
      - ./data:/srv/data
      - ./static:/srv/static
      - ./media:/srv/media
      - ./backend/logs:/srv/backend/logs
      - ./frontend/build/:/srv/frontend/build
    ports:
      - "8000:8000"
    healthcheck:
      test: [ "CMD-SHELL", "nc -z localhost 8000 || exit 1" ]
      timeout: 30s
      interval: 5s
      retries: 3
      start_period: 120s
    cap_add:
      - SYS_TIME
    networks:
      - net
    stop_grace_period: 5s
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 30s
      restart_policy:
        condition: on-failure

  celery:
    hostname: celery
    image: localhost:5000/icelery:latest
    volumes:
      - ./data:/srv/data
      - ./static:/srv/static
      - ./media:/srv/media
      - ./backend/logs:/srv/backend/logs
      - ./entrypoint_celery.sh:/srv/entrypoint_celery.sh
    environment:
      - LOG_PREFIX=celery
    networks:
      - net
    stop_grace_period: 2s
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
    security_opt:
      - seccomp=unconfined
    cap_add:
      - SYS_ADMIN


  beat:
    hostname: beat
    image: localhost:5000/ibeat:latest
    volumes:
      - ./data:/srv/data
      - ./static:/srv/static
      - ./media:/srv/media
      - ./backend/logs:/srv/backend/logs
      - ./entrypoint_beat.sh:/srv/entrypoint_beat.sh
    environment:
      - LOG_PREFIX=beat
    networks:
      - net
    stop_grace_period: 2s
    deploy:
      replicas: 1
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure

#  flower:
#    hostname: flower
#    image: localhost:5000/iflower:latest
#    environment:
#      - FLOWER_USER=${FLOWER_USER}
#      - FLOWER_PASSWORD=${FLOWER_PASSWORD}
#    volumes:
#      - ./backend/logs:/srv/backend/logs
#      - ./entrypoint_flower.sh:/srv/entrypoint_flower.sh
#    ports:
#      - "5555:5555"
#    networks:
#      - net
#    deploy:
#      replicas: 1
#      update_config:
#        parallelism: 1
#        delay: 10s
#      restart_policy:
#        condition: on-failure
#      resources:
#        limits:
#          cpus: '0.5'
#          memory: 256M
#        reservations:
#          cpus: '0.25'
#          memory: 128M

  # --- sonar stack -------------------------------------------------
  sonardb:
    image: postgres:16-alpine
    hostname: sonardb
    environment:
      - POSTGRES_USER=sonar
      - POSTGRES_PASSWORD=sonar
      - POSTGRES_DB=sonar
    volumes:
      - ./data/sonar_db:/var/lib/postgresql/data
    networks: [ net ]
    deploy:
      replicas: 1
      restart_policy: { condition: on-failure }

  sonarqube:
    image: sonarqube:10.5.1-community
    sysctls:
      - vm.max_map_count=262144
      - fs.file-max=131072
    ulimits:
      nproc: 8192
      nofile:
        soft: 131072
        hard: 131072
    hostname: sonarqube
    depends_on: [ sonardb ]
    environment:
      - SONAR_JDBC_URL=jdbc:postgresql://sonardb:5432/sonar
      - SONAR_JDBC_USERNAME=sonar
      - SONAR_JDBC_PASSWORD=sonar
    volumes:
      - ./data/sonarqube/data:/opt/sonarqube/data
      - ./data/sonarqube/extensions:/opt/sonarqube/extensions
      - ./data/sonarqube/logs:/opt/sonarqube/logs
    networks: [ net ]
    deploy:
      replicas: 1
      restart_policy: { condition: on-failure }

networks:
  net:
    driver: overlay
